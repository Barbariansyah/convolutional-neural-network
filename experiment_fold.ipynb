{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('venv')",
   "display_name": "Python 3.8.5 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "85010179ef5cdebc846897ca4f4c738543d2b56a7bddf26d874f73dc26532254"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Tugas Besar 1 CNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Eksperimen dengan split train dan test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from cnn.cnn import MyCnn\n",
    "from cnn.layers import Conv2D, Pooling, Dense, Flatten\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant\n",
    "IMG_HEIGHT, IMG_WIDTH = 64, 64\n",
    "TRAIN_IMG_DIR = './dataset/train'\n",
    "TEST_IMG_DIR = './dataset/test'\n",
    "SEED = 6459164\n",
    "SIGMOID_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def save_model(model, namefile: str):\n",
    "    model_file = open('cnn_model', 'ab')\n",
    "    pickle.dump(model, model_file)\n",
    "    model_file.close()\n",
    "\n",
    "\n",
    "def load_model(namefile: str):\n",
    "    model_file = open('cnn_model', 'rb')\n",
    "    model = pickle.load(model_file)\n",
    "    model_file.close()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_img_as_train_dataset() -> np.array:\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        TRAIN_IMG_DIR,\n",
    "        seed=SEED,\n",
    "        image_size=(IMG_HEIGHT, IMG_WIDTH)\n",
    "    )\n",
    "\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for img_batch, label_batch in train_ds:\n",
    "        imgs.append(img_batch.numpy())\n",
    "        labels.append(label_batch.numpy())\n",
    "\n",
    "    imgs = np.concatenate(imgs)\n",
    "    labels = np.concatenate(labels)\n",
    "\n",
    "    return imgs, labels\n",
    "\n",
    "\n",
    "def load_img_as_test_dataset() -> np.array:\n",
    "    test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        TEST_IMG_DIR,\n",
    "        seed=SEED,\n",
    "        image_size=(IMG_HEIGHT, IMG_WIDTH)\n",
    "    )\n",
    "\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for img_batch, label_batch in test_ds:\n",
    "        imgs.append(img_batch.numpy())\n",
    "        labels.append(label_batch.numpy())\n",
    "\n",
    "    imgs = np.concatenate(imgs)\n",
    "    labels = np.concatenate(labels)\n",
    "\n",
    "    return imgs, labels\n",
    "\n",
    "\n",
    "def normalize_img(img: np.array) -> np.array:\n",
    "    scalev = np.vectorize(lambda x: x / 255.0)\n",
    "    return scalev(img)\n",
    "\n",
    "\n",
    "def reorganize_layer(img: np.array) -> List[np.array]:\n",
    "    input_shape = img.shape\n",
    "    rows = input_shape[0]\n",
    "    cols = input_shape[1]\n",
    "    depth = input_shape[2]\n",
    "\n",
    "    layers = [np.array([[0] * cols] * rows) for _ in range(depth)]\n",
    "\n",
    "    for i, row in enumerate(img):\n",
    "        for j, col in enumerate(row):\n",
    "            for k, val in enumerate(col):\n",
    "                layers[k][i][j] = val\n",
    "\n",
    "    return layers\n",
    "\n",
    "\n",
    "def interpret_class(res: List[np.array]) -> int:\n",
    "    return 0 if res[0][0] < SIGMOID_THRESHOLD else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 181 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load Images\n",
    "imgs, labels = load_img_as_train_dataset()\n",
    "labels = list(labels)\n",
    "\n",
    "img_list = []\n",
    "for img in imgs:\n",
    "    img_norm = normalize_img(img)\n",
    "    img_reorganized = reorganize_layer(img)\n",
    "    img_list.append(img_reorganized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-165b3197020b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "kf = KFold(n_splits=10, random_state=SEED, shuffle=False)\n",
    "scores = []\n",
    "for train_index, test_index in kf.split(img_list):\n",
    "    # Model\n",
    "    cnn = MyCnn()\n",
    "    cnn.add(Conv2D(0, 4, np.array([3, 3]), 1, np.array(\n",
    "        [[IMG_HEIGHT, IMG_WIDTH] for _ in range(3)])))\n",
    "    cnn.add(Pooling(np.array([2, 2]), 2, 'max'))\n",
    "    cnn.add(Flatten())\n",
    "    cnn.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "    # Data\n",
    "    x_train, x_test = np.array(img_list)[train_index], np.array(img_list)[test_index]\n",
    "    y_train, y_test = np.array(labels)[train_index], np.array(labels)[test_index]\n",
    "\n",
    "    cnn.fit(x_train, y_train, 10, 10, 0.1, 0.01)\n",
    "\n",
    "    # Predict\n",
    "    res_class = []\n",
    "    for img, label in zip(x_test, y_test):\n",
    "        res, layers_input = cnn.feed_forward(img)\n",
    "        res_class.append(res_class)\n",
    "    \n",
    "    scores.append(accuracy_score(y_test, res_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print scores\n",
    "print(scores)"
   ]
  }
 ]
}